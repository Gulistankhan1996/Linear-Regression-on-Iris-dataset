{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "kQBxLxFjZ2OJ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def logistic_regression_prediction(weight, feature_vector):\n",
        "    z = np.dot(weight, feature_vector.T)\n",
        "    prediction = 1 / (1 + np.exp(-z))\n",
        "\n",
        "    return prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "EbsvmVI_aEiw"
      },
      "outputs": [],
      "source": [
        "def logistic_loss(predictions, actual_values):\n",
        "    predictions = np.array(predictions)\n",
        "    epsilon = 1e-15  # A very small value to avoid taking the logarithm of zero\n",
        "    predictions = np.clip(predictions, epsilon, 1 - epsilon)\n",
        "    loss = -np.mean(actual_values * np.log2(predictions) + (1 - actual_values) * np.log2(1 - predictions))\n",
        "\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Qr9N7YpDaEmH"
      },
      "outputs": [],
      "source": [
        "def gradient_of_logistic_loss(predictions, actual_values, feature_vector):\n",
        "    gradient = np.dot(feature_vector.T, (predictions - actual_values)) / actual_values.size\n",
        "\n",
        "    return gradient"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "vFmdiZAdaE1i"
      },
      "outputs": [],
      "source": [
        "def gradient_descent(weight,gradient,feature_vector, actual_values, stopping_criterion):\n",
        "\n",
        "    for i in range(stopping_criterion):\n",
        "        weight = weight - 0.01 * gradient\n",
        "        gradient = gradient_of_logistic_loss(logistic_regression_prediction(weight, feature_vector), actual_values, feature_vector)\n",
        "    return weight\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "czvokMAkaE9C",
        "outputId": "b33a1c3e-20cc-43a9-b3da-907e3596a3ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted  |  Actual\n",
            "---------------------\n",
            " 0.000059  |  0.0\n",
            " 0.999527  |  1.0\n",
            " 0.000000  |  0.0\n",
            " 0.000096  |  0.0\n",
            " 0.000044  |  0.0\n",
            " 0.999056  |  1.0\n",
            " 0.005293  |  0.0\n",
            " 0.000005  |  0.0\n",
            " 0.000015  |  0.0\n",
            " 0.001159  |  0.0\n",
            " 0.000009  |  0.0\n",
            " 0.998338  |  1.0\n",
            " 0.999815  |  1.0\n",
            " 0.998208  |  1.0\n",
            " 0.999686  |  1.0\n",
            " 0.000129  |  0.0\n",
            " 0.000000  |  0.0\n",
            " 0.000687  |  0.0\n",
            " 0.000085  |  0.0\n",
            " 0.000000  |  0.0\n",
            " 0.997034  |  1.0\n",
            " 0.000013  |  0.0\n",
            " 0.998015  |  1.0\n",
            " 0.000000  |  0.0\n",
            " 0.000001  |  0.0\n",
            " 0.000002  |  0.0\n",
            " 0.000000  |  0.0\n",
            " 0.000000  |  0.0\n",
            " 0.997534  |  1.0\n",
            " 0.996357  |  1.0\n",
            "Class 0: Accuracy=30/30, Loss=0.0012\n",
            "Predicted  |  Actual\n",
            "---------------------\n",
            " 0.671359  |  1.0\n",
            " 0.061847  |  0.0\n",
            " 0.763911  |  0.0\n",
            " 0.386829  |  1.0\n",
            " 0.631536  |  1.0\n",
            " 0.102398  |  0.0\n",
            " 0.280107  |  1.0\n",
            " 0.115327  |  0.0\n",
            " 0.807764  |  1.0\n",
            " 0.537306  |  1.0\n",
            " 0.152557  |  0.0\n",
            " 0.335575  |  0.0\n",
            " 0.106605  |  0.0\n",
            " 0.304731  |  0.0\n",
            " 0.044195  |  0.0\n",
            " 0.186257  |  1.0\n",
            " 0.268131  |  0.0\n",
            " 0.700908  |  1.0\n",
            " 0.545673  |  1.0\n",
            " 0.333500  |  0.0\n",
            " 0.216898  |  0.0\n",
            " 0.264651  |  0.0\n",
            " 0.100603  |  0.0\n",
            " 0.387065  |  0.0\n",
            " 0.155786  |  0.0\n",
            " 0.149568  |  0.0\n",
            " 0.785383  |  0.0\n",
            " 0.170060  |  0.0\n",
            " 0.240756  |  0.0\n",
            " 0.270351  |  0.0\n",
            "Class 1: Accuracy=25/30, Loss=0.6686\n",
            "Predicted  |  Actual\n",
            "---------------------\n",
            " 0.028900  |  0.0\n",
            " 0.000000  |  0.0\n",
            " 0.999995  |  1.0\n",
            " 0.044996  |  0.0\n",
            " 0.010487  |  0.0\n",
            " 0.000000  |  0.0\n",
            " 0.000204  |  0.0\n",
            " 0.730848  |  1.0\n",
            " 0.527388  |  0.0\n",
            " 0.001026  |  0.0\n",
            " 0.551000  |  1.0\n",
            " 0.000000  |  0.0\n",
            " 0.000000  |  0.0\n",
            " 0.000000  |  0.0\n",
            " 0.000000  |  0.0\n",
            " 0.009238  |  0.0\n",
            " 0.999239  |  1.0\n",
            " 0.003960  |  0.0\n",
            " 0.076629  |  0.0\n",
            " 0.999417  |  1.0\n",
            " 0.000000  |  0.0\n",
            " 0.614063  |  1.0\n",
            " 0.000000  |  0.0\n",
            " 0.998899  |  1.0\n",
            " 0.334842  |  1.0\n",
            " 0.955539  |  1.0\n",
            " 0.998709  |  1.0\n",
            " 0.997661  |  1.0\n",
            " 0.000000  |  0.0\n",
            " 0.000000  |  0.0\n",
            "Class 2: Accuracy=28/30, Loss=0.1670\n"
          ]
        }
      ],
      "source": [
        "from sklearn import datasets\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Load Iris dataset\n",
        "iris = datasets.load_iris()\n",
        "X = iris[\"data\"]\n",
        "y = iris[\"target\"]\n",
        "\n",
        "\n",
        "X = np.hstack([np.ones((X.shape[0], 1)), X])\n",
        "# Split the data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "# Initialize weight vector\n",
        "weight = np.zeros(X_train.shape[1])\n",
        "\n",
        "# Train the model\n",
        "for i in np.unique(y):\n",
        "    y_train_binary = np.where(y_train == i, 1, 0)\n",
        "    y_test_binary = np.where(y_test == i, 1, 0)\n",
        "\n",
        "    weight = gradient_descent(weight,gradient_of_logistic_loss(logistic_regression_prediction(weight, X_train),y_train_binary,X_train), X_train, y_train_binary,100000)\n",
        "    predictions = logistic_regression_prediction(weight, X_test)\n",
        "\n",
        "\n",
        "    correct_predictions = sum((np.array(predictions) >= 0.5) == y_test_binary)\n",
        "    accuracy = correct_predictions / len(y_test_binary)\n",
        "\n",
        "    # Calculate loss\n",
        "    loss = logistic_loss(predictions, y_test_binary)\n",
        "\n",
        "    combined_data = np.vstack((predictions, y_test_binary)).T\n",
        "    # Print with aligned columns\n",
        "    print(\"Predicted  |  Actual\")\n",
        "    print(\"---------------------\")\n",
        "    for row in combined_data:\n",
        "        print(f\"{row[0]:9.6f}  |  {row[1]}\")\n",
        "    print(f'Class {i}: Accuracy={correct_predictions}/{len(y_test_binary)}, Loss={loss:.4f}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L4Tw1cr-YvZL"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Accuracy increases with changing the learning rate and increasing interations.**"
      ],
      "metadata": {
        "id": "DXmPEYv7BNmt"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oAzKfPmVBxiM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xE2UCU_YB1sJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}